{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating synonym and not synonym dataset using wordnet\n",
    "\n",
    "First let's create a dataset of pairs of words that are synonyms or not synonyms using wordnet's synsets.\n",
    "\n",
    "*Note*: \"not synonyms\" is not equivalent of antonyms, it simply means selecting any word `w2` in `(w1, w2)` pair in which the word `w2` is not in the set of synonyms to `w1`, i.e. we are simply performing **negative sampling**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import random\n",
    "\n",
    "import networkx as nx \n",
    "from nltk.corpus import wordnet as wn\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synsets(part_of_speeches=None, verbose=True):\n",
    "    \"\"\"\n",
    "    returns a dictionary where key is a particular part of speech\n",
    "    and value is the list of all synsets in that POS, if default\n",
    "    `part_of_speeches` is `None`, will use, verb, noun and adjectives.\n",
    "    \"\"\"\n",
    "    if part_of_speeches is None:\n",
    "        part_of_speeches={'verb': 'v', 'noun': 'n', 'adjective': 'a'}\n",
    "        \n",
    "    pos_synsets = dict()\n",
    "    for name, pos in part_of_speeches.items():\n",
    "        pos_synsets[name] = list(wn.all_synsets(pos))\n",
    "        if verbose:\n",
    "            print(f\"found {len(pos_synsets[name])} synsets for {name}\")\n",
    "    return pos_synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_synsets = get_synsets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_single_word(word):\n",
    "    \"\"\"\n",
    "    For removing lemma names that contains multiple words, \n",
    "    separated by `-` or `_` \n",
    "    \"\"\"\n",
    "    return (('_' not in word) and ('-' not in word))\n",
    "\n",
    "syn_graphs = dict()\n",
    "all_words = dict()\n",
    "for pos, val in pos_synsets.items():\n",
    "    syn_graphs[pos] = nx.Graph()\n",
    "    for synset in val:\n",
    "        lemma_names = [x for x in synset.lemma_names() if is_single_word(x)]\n",
    "        if len(lemma_names) > 1:\n",
    "            syn_graphs[pos].add_edges_from(combinations(lemma_names, 2))\n",
    "    all_words[pos] = set(syn_graphs[pos].nodes)\n",
    "    print(f\"Found {len(syn_graphs[pos].edges)} synonym pairs and {len(all_words[pos])} unique words in {pos}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(syn_graphs['verb'].neighbors('change')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(syn_graphs['noun'].neighbors('ocean')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(syn_graphs['adjective'].neighbors('large')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_verb_subgraph(subset=['change', 'buy']):\n",
    "    nodes = []\n",
    "    for word in subset:\n",
    "        nodes.append(word)\n",
    "        nodes.extend(list(syn_graphs['verb'].neighbors(word)))\n",
    "    subgraph = syn_graphs['verb'].subgraph(nodes)\n",
    "    return subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph = get_verb_subgraph(subset=['sell', 'buy', 'change'])\n",
    "pos=nx.spring_layout(subgraph, iterations=150, k=1.5)\n",
    "nx.draw(subgraph, pos=pos)\n",
    "nx.draw_networkx_labels(subgraph, pos=pos, font_size=10)\n",
    "plt.show()\n",
    "# plt.savefig('graph.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
