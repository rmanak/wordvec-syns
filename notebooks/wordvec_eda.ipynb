{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from nltk.corpus import wordnet as wn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "from random import shuffle\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg', disable=['parser', 'tagger', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_words = set()\n",
    "for pos in ['v', 'n', 'a']:\n",
    "    for synset in wn.all_synsets(pos):\n",
    "        lemma_names = [x for x in synset.lemma_names() if x.isalpha()]\n",
    "        all_words.update(lemma_names)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_vectors = dict()\n",
    "for word in all_words:\n",
    "    word_nlp = nlp(word.lower())[0]\n",
    "    has_vector, vector = word_nlp.has_vector, word_nlp.vector\n",
    "    if has_vector:\n",
    "        word_vectors[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordvec_matrix = np.zeros((len(word_vectors), 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_index = dict()\n",
    "word_vec_tuples = list(word_vectors.items())\n",
    "shuffle(word_vec_tuples)\n",
    "for (index, (word, vec)) in enumerate(word_vec_tuples):\n",
    "    word_index[word] = index\n",
    "    wordvec_matrix[index, :] = vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalized_wordvec_matrix = wordvec_matrix / np.linalg.norm(wordvec_matrix, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_cosine_sim = np.dot(normalized_wordvec_matrix[:1000,:], normalized_wordvec_matrix[:1000,:].T)\n",
    "word_cosine_sim = np.tril(word_cosine_sim, -1)\n",
    "word_cosine_sim = word_cosine_sim[np.nonzero(word_cosine_sim)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(word_cosine_sim, bins=100, normed=True, alpha=0.5, label='random')\n",
    "plt.title(\"dist. of cosine similarity of randomly chosen words\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../datasets/synonym_dataset.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pair_has_wordvec(row):\n",
    "    return (row['word1'] in word_vectors) and (row['word2'] in word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['has_word_vec'] = data.apply(pair_has_wordvec, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.loc[data.has_word_vec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(row):\n",
    "    v1 = word_vectors[row['word1']]\n",
    "    v2 = word_vectors[row['word2']]\n",
    "    return np.dot(v1, v2)/(np.linalg.norm(v1)*np.linalg.norm(v1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['cosine'] = data.apply(cosine_similarity, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lbl in ['train', 'test']:\n",
    "    df = data.loc[data.split==lbl]\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.subplot(121)\n",
    "    plt.hist(df.loc[df.synonym==1, 'cosine'], bins=100, \n",
    "             color='steelblue', normed=False, label='synonym')\n",
    "\n",
    "    plt.hist(df.loc[df.synonym==0, 'cosine'], bins=100, \n",
    "             color='seagreen', normed=False, alpha=0.5, \n",
    "             label='not synonym')\n",
    "\n",
    "    plt.hist(word_cosine_sim, bins=100, color='red', normed=False, alpha=0.5, label='random')\n",
    "\n",
    "    plt.title(\"count dist of cosine similarity of word vectors ({} set)\".format(lbl), fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"cosine similarity\")\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plt.hist(df.loc[df.synonym==1, 'cosine'], bins=100, \n",
    "             color='steelblue', normed=True, label='synonym')\n",
    "\n",
    "    plt.hist(df.loc[df.synonym==0, 'cosine'], bins=100, \n",
    "             color='seagreen', normed=True, alpha=0.5, \n",
    "             label='not synonym')\n",
    "\n",
    "    plt.hist(word_cosine_sim, bins=100, color='red', normed=True, alpha=0.5, label='random')\n",
    "\n",
    "    plt.title(\"normalized distribution of cosine similarity of word vectors({} set)\".format(lbl), fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"cosine similarity\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = data.loc[data.split=='train'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(roc_auc_score(df['synonym'], df['cosine']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "span_space = np.linspace(0.05, 0.95, 100)\n",
    "for threshold in span_space:\n",
    "    df['pred_syn'] = 0\n",
    "    df.loc[df.cosine > threshold, 'pred_syn'] = 1\n",
    "    accuracy_scores.append(accuracy_score(df['synonym'], df['pred_syn']))\n",
    "    precision_scores.append(precision_score(df['synonym'], df['pred_syn']))\n",
    "    recall_scores.append(recall_score(df['synonym'], df['pred_syn']))\n",
    "    f1_scores.append(f1_score(df['synonym'], df['pred_syn']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(span_space, np.array(accuracy_scores), fit_reg=False)\n",
    "plt.xlabel(\"classification threshold\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(np.array(recall_scores), np.array(precision_scores), fit_reg=False)\n",
    "plt.xlabel(\"recall\")\n",
    "plt.ylabel(\"precision\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(np.array(span_space), np.array(f1_scores), fit_reg=False)\n",
    "plt.xlabel(\"threshold\")\n",
    "plt.ylabel(\"f1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_f1_threshold, best_f1_val = span_space[np.argmax(f1_scores)], np.max(f1_scores)\n",
    "print(\"best threshold: {} best f1 score: {} \".format(best_f1_threshold, best_f1_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = data.loc[data.split=='test'].copy()\n",
    "df_test['pred_syn'] = 0\n",
    "df_test.loc[df_test.cosine > best_f1_threshold, 'pred_syn'] = 1\n",
    "print(\"f1 score in test set using best threshold: {}\".format(f1_score(df_test.synonym, df_test.pred_syn)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
